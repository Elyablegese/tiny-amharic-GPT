{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('First Citizen:\\n'\n",
      " 'Before we proceed any further, hear me speak.\\n'\n",
      " '\\n'\n",
      " 'All:\\n'\n",
      " 'Speak, speak.\\n'\n",
      " '\\n'\n",
      " 'First Citizen:\\n'\n",
      " 'You are all resolved rather to die than to famish?\\n'\n",
      " '\\n'\n",
      " 'All:\\n'\n",
      " 'Resolved. resolved.\\n'\n",
      " '\\n'\n",
      " 'First Citizen:\\n'\n",
      " 'First, you know Caius Marcius is chief enemy to the people.\\n'\n",
      " '\\n'\n",
      " 'All:\\n'\n",
      " \"We know't, we know't.\\n\"\n",
      " '\\n'\n",
      " 'First Citizen:\\n'\n",
      " \"Let us kill him, and we'll have corn at our own price.\\n\"\n",
      " \"Is't a verdict?\\n\"\n",
      " '\\n'\n",
      " 'All:\\n'\n",
      " \"No more talking on't; let it be done: away, away!\\n\"\n",
      " '\\n'\n",
      " 'Second Citizen:\\n'\n",
      " 'One word, good citizens.\\n'\n",
      " '\\n'\n",
      " 'First Citizen:\\n'\n",
      " 'We are accounted poor citizens, the patricians good.\\n'\n",
      " 'What authority surfeits on would relieve us: if they\\n'\n",
      " 'would yield us but the superfluity, while it were\\n'\n",
      " 'wholesome, we might guess they relieved us humanely;\\n'\n",
      " 'but they think we are too dear: the leanness that\\n'\n",
      " 'afflicts us, the object of our misery, is as an\\n'\n",
      " 'inventory to particularise their abundance; our\\n'\n",
      " 'sufferance is a gain to them Let us revenge this with\\n'\n",
      " 'our pikes, ere we become rakes: for the gods know I\\n'\n",
      " 'speak this in hunger for bread, not in thirst for revenge.\\n'\n",
      " '\\n')\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/input.txt\",\"r\",encoding=\"utf-8\")as f:\n",
    "    text=f.read()\n",
    "len(text)\n",
    "pprint.pprint(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "char=sorted(list(set(text)))\n",
    "vocab_size=len(char)\n",
    "print(\"\".join(char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder and decoder\n",
    "stoi={s:i for i,s in enumerate(char)}\n",
    "itos={i:s for i,s in enumerate(char)}\n",
    "encode= lambda s: [stoi[c] for c in s]\n",
    "decode= lambda l: \"\".join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode all the text\n",
    "data=torch.tensor(encode(text),dtype=torch.long)\n",
    "data[:1000]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(0.9*len(text))\n",
    "train_data=data[:n]\n",
    "val_data=data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input is  tensor([18]) target is  47\n",
      "input is  tensor([18, 47]) target is  56\n",
      "input is  tensor([18, 47, 56]) target is  57\n",
      "input is  tensor([18, 47, 56, 57]) target is  58\n",
      "input is  tensor([18, 47, 56, 57, 58]) target is  1\n",
      "input is  tensor([18, 47, 56, 57, 58,  1]) target is  15\n",
      "input is  tensor([18, 47, 56, 57, 58,  1, 15]) target is  47\n",
      "input is  tensor([18, 47, 56, 57, 58,  1, 15, 47]) target is  58\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47])\n",
      "tensor([47, 56, 57, 58,  1, 15, 47, 58])\n"
     ]
    }
   ],
   "source": [
    "#viz of block of words\n",
    "block_size=8\n",
    "x=train_data[:block_size]\n",
    "y=train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context=x[:t+1]\n",
    "    target=y[t]\n",
    "    \n",
    "    print(f\"input is  {context} target is  {target}\")\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  torch.Size([4, 8])\n",
      "input:  tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "output shape:  torch.Size([4, 8])\n",
      "output:  tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "--------------------------------------------------------------------\n",
      "input is  tensor([24]) target is  43\n",
      "input is  tensor([24, 43]) target is  58\n",
      "input is  tensor([24, 43, 58]) target is  5\n",
      "input is  tensor([24, 43, 58,  5]) target is  57\n",
      "input is  tensor([24, 43, 58,  5, 57]) target is  1\n",
      "input is  tensor([24, 43, 58,  5, 57,  1]) target is  46\n",
      "input is  tensor([24, 43, 58,  5, 57,  1, 46]) target is  43\n",
      "input is  tensor([24, 43, 58,  5, 57,  1, 46, 43]) target is  39\n",
      "input is  tensor([44]) target is  53\n",
      "input is  tensor([44, 53]) target is  56\n",
      "input is  tensor([44, 53, 56]) target is  1\n",
      "input is  tensor([44, 53, 56,  1]) target is  58\n",
      "input is  tensor([44, 53, 56,  1, 58]) target is  46\n",
      "input is  tensor([44, 53, 56,  1, 58, 46]) target is  39\n",
      "input is  tensor([44, 53, 56,  1, 58, 46, 39]) target is  58\n",
      "input is  tensor([44, 53, 56,  1, 58, 46, 39, 58]) target is  1\n",
      "input is  tensor([52]) target is  58\n",
      "input is  tensor([52, 58]) target is  1\n",
      "input is  tensor([52, 58,  1]) target is  58\n",
      "input is  tensor([52, 58,  1, 58]) target is  46\n",
      "input is  tensor([52, 58,  1, 58, 46]) target is  39\n",
      "input is  tensor([52, 58,  1, 58, 46, 39]) target is  58\n",
      "input is  tensor([52, 58,  1, 58, 46, 39, 58]) target is  1\n",
      "input is  tensor([52, 58,  1, 58, 46, 39, 58,  1]) target is  46\n",
      "input is  tensor([25]) target is  17\n",
      "input is  tensor([25, 17]) target is  27\n",
      "input is  tensor([25, 17, 27]) target is  10\n",
      "input is  tensor([25, 17, 27, 10]) target is  0\n",
      "input is  tensor([25, 17, 27, 10,  0]) target is  21\n",
      "input is  tensor([25, 17, 27, 10,  0, 21]) target is  1\n",
      "input is  tensor([25, 17, 27, 10,  0, 21,  1]) target is  54\n",
      "input is  tensor([25, 17, 27, 10,  0, 21,  1, 54]) target is  39\n"
     ]
    }
   ],
   "source": [
    "# we added random batchs\n",
    "torch.manual_seed(1337)\n",
    "batch_size=4\n",
    "block_size=8\n",
    "\n",
    "# generate batch of data of x and y\n",
    "def get_batch(split):\n",
    "    data =train_data if split == \"train\" else val_data\n",
    "    ix=torch.randint(len(data)-block_size,(batch_size,)) \n",
    "    x=torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y=torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb,yb=get_batch(\"train\")\n",
    "print(\"input shape: \" ,xb.shape)\n",
    "print(\"input: \" ,xb)\n",
    "print(\"output shape: \",yb.shape)\n",
    "print(\"output: \",yb)\n",
    "\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):  \n",
    "        context=xb[b,:t+1]\n",
    "        target=yb[b,t]\n",
    "        print(f\"input is  {context} target is  {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then feed it to NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': tensor(4.6346), 'val': tensor(4.6015)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_loss():\n",
    "    out = {}\n",
    "    m.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(200)\n",
    "        for k in range(200):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = m(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    m.train()\n",
    "    return out\n",
    "estimate_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65]) tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embed_tabel=nn.Embedding(vocab_size,vocab_size)\n",
    "    \n",
    "    def forward(self,idx,targets=None):#id and and target are integer tensor\n",
    "        logits=self.token_embed_tabel(idx)  # B,T,C  ->  (batch,time(block),channels(vocab))\n",
    "        \n",
    "        if targets is None:\n",
    "            loss=None\n",
    "        else:\n",
    "            #pytorch arrange it differnt way and the dimension\n",
    "            B,T,C=logits.shape\n",
    "            logits=logits.view(B*T,C)\n",
    "            targets=targets.view(B*T)\n",
    "            loss=F.cross_entropy(logits,targets)\n",
    "        \n",
    "        return logits,loss\n",
    "\n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits,loss=self(idx)   #get the prediction         \n",
    "            logits=logits[:,-1,:]   # focus only in the last time stamp -> becomes( B*C )\n",
    "            probs=F.softmax(logits,dim=-1) #get prob\n",
    "            idx_next=torch.multinomial(probs,num_samples=1)\n",
    "            idx=torch.cat((idx,idx_next), dim=1)\n",
    "            #print(idx)\n",
    "        return idx\n",
    "        \n",
    "m=BigramLanguageModel(vocab_size)\n",
    "\n",
    "# the target is assigned\n",
    "logits,loss=m(xb,yb)\n",
    "print(logits.shape,loss)     #we are expecting -ln(1/65) loss\n",
    "\n",
    "\n",
    "generated=m.generate(idx = torch.zeros((1, 1), dtype=torch.long),max_new_tokens=100)[0].tolist()\n",
    "print(decode(generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.587916374206543\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "batch_size=32\n",
    "optimizer=torch.optim.AdamW(m.parameters(),lr=1e-3)\n",
    "\n",
    "for steps in range(100):\n",
    "    xb,yb=get_batch(\"train\")\n",
    "\n",
    "    logits,loss=m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relatable result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xiKi-RJ:CgqVuUa!U?qMH.uk!sCuMXvv!CJFfx;LgRyJknOEti.?I&-gPlLyulId?XlaInQ'q,lT$\n",
      "3Q&sGlvHQ?mqSq-eON\n",
      "x?SP fUAfCAuCX:bOlgiRQWN:Mphaw\n",
      "tRLKuYXEaAXxrcq-gCUzeh3w!AcyaylgYWjmJM?Uzw:inaY,:C&OECW:vmGGJAn3onAuMgia!ms$Vb q-gCOcPcUhOnxJGUGSPJWT:.?ujmJFoiNL&A'DxY,prZ?qdT;hoo'dHooXXlxf'WkHK&u3Q?rqUi.kz;?Yx?C&u3Qbfzxlyh'Vl:zyxjKXgC?\n",
      "lv'QKFiBeviNxO'm!Upm$srm&TqViqiBD3HBP!juEOpmZJyF$Fwfy!PlvWPFC\n",
      "&WDdP!Ko,px\n",
      "x\n",
      "tREOE;A\n"
     ]
    }
   ],
   "source": [
    "#preview the result\n",
    "generated=m.generate(idx = torch.zeros((1, 1), dtype=torch.long),max_new_tokens=400)[0].tolist()\n",
    "print(decode(generated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C=4,8,2\n",
    "x=torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version1 average of each previous token\n",
    "# for loop is not efficient\n",
    "xbow=torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev=x[b,:t+1] #(t,C)\n",
    "        xbow[b,t]=torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version2 matrix multiplication\n",
    "# we can do average easily\n",
    "\n",
    "wei= torch.tril(torch.ones(T,T)) # diagonal triangle half zero\n",
    "wei= wei / wei.sum(1,keepdim=True) #normalize it\n",
    "xbow2= wei @ x\n",
    "\n",
    "# torch.allclose(xbow,xbow2)\n",
    "'''\n",
    "The difference arises from floating-point precision. \n",
    "The division operation in creating wei and the subsequent \n",
    "matrix multiplication can introduce small floating-point errors.\n",
    "'''\n",
    "torch.allclose(xbow, xbow2, atol=1e-6, rtol=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version 3\n",
    "#we use this version more inthe transformer\n",
    "tril=torch.tril(torch.ones(T,T))\n",
    "wei=torch.zeros((T,T))\n",
    "wei=wei.masked_fill(tril[:T,:T]==0,float('-inf'))\n",
    "# wei=F.softmax(wei,dim=-1)\n",
    "xbow3=wei @ x\n",
    "\n",
    "torch.allclose(xbow, xbow3, atol=1e-6, rtol=1e-5)\n",
    "\n",
    "wei\n",
    "\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data/image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version 4\n",
    "torch.manual_seed(1337)\n",
    "B,T,C=4,8,32\n",
    "x=torch.randn(B,T,C)\n",
    "\n",
    "#single head self attention\n",
    "\n",
    "head_size=16\n",
    "key=nn.Linear(C,head_size,bias=False)\n",
    "query=nn.Linear(C,head_size,bias=False)\n",
    "value=nn.Linear(C,head_size,bias=False)\n",
    "k=key(x)\n",
    "q=query(x)\n",
    "v=value(x)\n",
    "''' \n",
    "the inner dimensions must match. For two matrices A and B to be multiplied, \n",
    "the number of columns in A must equal the number of rows in B.\n",
    "'''\n",
    "wei=q@k.transpose(-2,-1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril=torch.tril(torch.ones(T,T))\n",
    "# wei=torch.zeros((T,T))\n",
    "''' \n",
    "we dont want this to be uniform(must be data dependent)\n",
    "so we each token have two vectors query and key \n",
    "'''\n",
    "wei=wei.masked_fill(tril==0,float('-inf')) # wei masked fill of tril 0 to -inf\n",
    "wei=F.softmax(wei,dim=-1) #normilize each row \n",
    "out=wei @ v\n",
    "out.shape\n",
    "wei[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
